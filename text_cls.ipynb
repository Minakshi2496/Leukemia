{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbaf58f5-d049-4f6c-9680-c5f9346d9053",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.13.0-py3-none-any.whl (3.3 MB)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\owner\\anaconda3\\lib\\site-packages (from transformers) (4.59.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\owner\\anaconda3\\lib\\site-packages (from transformers) (20.9)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\owner\\anaconda3\\lib\\site-packages (from transformers) (2021.4.4)\n",
      "Requirement already satisfied: requests in c:\\users\\owner\\anaconda3\\lib\\site-packages (from transformers) (2.25.1)\n",
      "Collecting sacremoses\n",
      "  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.1.0\n",
      "  Downloading huggingface_hub-0.2.1-py3-none-any.whl (61 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\owner\\anaconda3\\lib\\site-packages (from transformers) (1.20.1)\n",
      "Collecting tokenizers<0.11,>=0.10.1\n",
      "  Downloading tokenizers-0.10.3-cp38-cp38-win_amd64.whl (2.0 MB)\n",
      "Requirement already satisfied: filelock in c:\\users\\owner\\anaconda3\\lib\\site-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\owner\\anaconda3\\lib\\site-packages (from transformers) (5.4.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\owner\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.7.4.3)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\owner\\anaconda3\\lib\\site-packages (from packaging>=20.0->transformers) (2.4.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\owner\\anaconda3\\lib\\site-packages (from requests->transformers) (2020.12.5)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\owner\\anaconda3\\lib\\site-packages (from requests->transformers) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\owner\\anaconda3\\lib\\site-packages (from requests->transformers) (1.26.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\owner\\anaconda3\\lib\\site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: click in c:\\users\\owner\\anaconda3\\lib\\site-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: six in c:\\users\\owner\\anaconda3\\lib\\site-packages (from sacremoses->transformers) (1.15.0)\n",
      "Requirement already satisfied: joblib in c:\\users\\owner\\anaconda3\\lib\\site-packages (from sacremoses->transformers) (1.0.1)\n",
      "Installing collected packages: tokenizers, sacremoses, huggingface-hub, transformers\n",
      "Successfully installed huggingface-hub-0.2.1 sacremoses-0.0.46 tokenizers-0.10.3 transformers-4.13.0\n",
      "Requirement already satisfied: ipywidgets in c:\\users\\owner\\anaconda3\\lib\\site-packages (7.6.3)\n",
      "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in c:\\users\\owner\\anaconda3\\lib\\site-packages (from ipywidgets) (1.0.0)\n",
      "Requirement already satisfied: ipython>=4.0.0 in c:\\users\\owner\\anaconda3\\lib\\site-packages (from ipywidgets) (7.22.0)\n",
      "Requirement already satisfied: nbformat>=4.2.0 in c:\\users\\owner\\anaconda3\\lib\\site-packages (from ipywidgets) (5.1.3)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in c:\\users\\owner\\anaconda3\\lib\\site-packages (from ipywidgets) (5.0.5)\n",
      "Requirement already satisfied: widgetsnbextension~=3.5.0 in c:\\users\\owner\\anaconda3\\lib\\site-packages (from ipywidgets) (3.5.1)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in c:\\users\\owner\\anaconda3\\lib\\site-packages (from ipywidgets) (5.3.4)\n",
      "Requirement already satisfied: tornado>=4.2 in c:\\users\\owner\\anaconda3\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets) (6.1)\n",
      "Requirement already satisfied: jupyter-client in c:\\users\\owner\\anaconda3\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets) (6.1.12)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in c:\\users\\owner\\anaconda3\\lib\\site-packages (from ipython>=4.0.0->ipywidgets) (3.0.17)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\owner\\anaconda3\\lib\\site-packages (from ipython>=4.0.0->ipywidgets) (0.17.2)\n",
      "Requirement already satisfied: setuptools>=18.5 in c:\\users\\owner\\anaconda3\\lib\\site-packages (from ipython>=4.0.0->ipywidgets) (52.0.0.post20210125)\n",
      "Requirement already satisfied: pickleshare in c:\\users\\owner\\anaconda3\\lib\\site-packages (from ipython>=4.0.0->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: backcall in c:\\users\\owner\\anaconda3\\lib\\site-packages (from ipython>=4.0.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\owner\\anaconda3\\lib\\site-packages (from ipython>=4.0.0->ipywidgets) (0.4.4)\n",
      "Requirement already satisfied: decorator in c:\\users\\owner\\anaconda3\\lib\\site-packages (from ipython>=4.0.0->ipywidgets) (5.0.6)\n",
      "Requirement already satisfied: pygments in c:\\users\\owner\\anaconda3\\lib\\site-packages (from ipython>=4.0.0->ipywidgets) (2.8.1)\n",
      "Requirement already satisfied: parso<0.8.0,>=0.7.0 in c:\\users\\owner\\anaconda3\\lib\\site-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in c:\\users\\owner\\anaconda3\\lib\\site-packages (from nbformat>=4.2.0->ipywidgets) (3.2.0)\n",
      "Requirement already satisfied: ipython-genutils in c:\\users\\owner\\anaconda3\\lib\\site-packages (from nbformat>=4.2.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: jupyter-core in c:\\users\\owner\\anaconda3\\lib\\site-packages (from nbformat>=4.2.0->ipywidgets) (4.7.1)\n",
      "Requirement already satisfied: attrs>=17.4.0 in c:\\users\\owner\\anaconda3\\lib\\site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (20.3.0)\n",
      "Requirement already satisfied: six>=1.11.0 in c:\\users\\owner\\anaconda3\\lib\\site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (1.15.0)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in c:\\users\\owner\\anaconda3\\lib\\site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (0.17.3)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\owner\\anaconda3\\lib\\site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets) (0.2.5)\n",
      "Requirement already satisfied: notebook>=4.4.1 in c:\\users\\owner\\anaconda3\\lib\\site-packages (from widgetsnbextension~=3.5.0->ipywidgets) (6.3.0)\n",
      "Requirement already satisfied: pyzmq>=17 in c:\\users\\owner\\anaconda3\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (20.0.0)\n",
      "Requirement already satisfied: argon2-cffi in c:\\users\\owner\\anaconda3\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (20.1.0)\n",
      "Requirement already satisfied: Send2Trash>=1.5.0 in c:\\users\\owner\\anaconda3\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.5.0)\n",
      "Requirement already satisfied: nbconvert in c:\\users\\owner\\anaconda3\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (6.0.7)\n",
      "Requirement already satisfied: terminado>=0.8.3 in c:\\users\\owner\\anaconda3\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.9.4)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\owner\\anaconda3\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.11.3)\n",
      "Requirement already satisfied: prometheus-client in c:\\users\\owner\\anaconda3\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.10.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\owner\\anaconda3\\lib\\site-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets) (2.8.1)\n",
      "Requirement already satisfied: pywin32>=1.0 in c:\\users\\owner\\anaconda3\\lib\\site-packages (from jupyter-core->nbformat>=4.2.0->ipywidgets) (227)\n",
      "Requirement already satisfied: pywinpty>=0.5 in c:\\users\\owner\\anaconda3\\lib\\site-packages (from terminado>=0.8.3->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.5.7)\n",
      "Requirement already satisfied: cffi>=1.0.0 in c:\\users\\owner\\anaconda3\\lib\\site-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.14.5)\n",
      "Requirement already satisfied: pycparser in c:\\users\\owner\\anaconda3\\lib\\site-packages (from cffi>=1.0.0->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.20)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\owner\\anaconda3\\lib\\site-packages (from jinja2->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.1.1)\n",
      "Requirement already satisfied: nbclient<0.6.0,>=0.5.0 in c:\\users\\owner\\anaconda3\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.5.3)\n",
      "Requirement already satisfied: testpath in c:\\users\\owner\\anaconda3\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.4.4)\n",
      "Requirement already satisfied: bleach in c:\\users\\owner\\anaconda3\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (3.3.0)\n",
      "Requirement already satisfied: defusedxml in c:\\users\\owner\\anaconda3\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.7.1)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in c:\\users\\owner\\anaconda3\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.4.3)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in c:\\users\\owner\\anaconda3\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.3)\n",
      "Requirement already satisfied: jupyterlab-pygments in c:\\users\\owner\\anaconda3\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.1.2)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in c:\\users\\owner\\anaconda3\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: nest-asyncio in c:\\users\\owner\\anaconda3\\lib\\site-packages (from nbclient<0.6.0,>=0.5.0->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.5.1)\n",
      "Requirement already satisfied: async-generator in c:\\users\\owner\\anaconda3\\lib\\site-packages (from nbclient<0.6.0,>=0.5.0->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.10)\n",
      "Requirement already satisfied: packaging in c:\\users\\owner\\anaconda3\\lib\\site-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (20.9)\n",
      "Requirement already satisfied: webencodings in c:\\users\\owner\\anaconda3\\lib\\site-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.5.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\owner\\anaconda3\\lib\\site-packages (from packaging->bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.4.7)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "!pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cfe1107b-a6a9-4e77-86a7-e4a51c9fb70e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-fef126053eb8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# 从 transformers 引入 TFBertForSequenceClassification,BertTokenizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTFBertForSequenceClassification\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mBertTokenizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "#加载日志信息\n",
    "import logging\n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "# 从 transformers 引入 TFBertForSequenceClassification,BertTokenizer\n",
    "from transformers import TFBertForSequenceClassification,BertTokenizer\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a27625f2-570c-4561-9dcf-1628bd8f7415",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_example_to_feature(review):\n",
    "  \n",
    "    return tokenizer.encode_plus(review, \n",
    "                add_special_tokens = True, # 添加 [CLS], [SEP]\n",
    "                max_length = max_length, # bert使用的最大文本长度\n",
    "                pad_to_max_length = True, # 添加 [PAD] tokens\n",
    "                return_attention_mask = True, \n",
    "            truncation=True\n",
    "              )\n",
    "\n",
    "def map_example_to_dict(input_ids, attention_masks, token_type_ids, label):\n",
    "    return {\n",
    "      \"input_ids\": input_ids,\n",
    "      \"token_type_ids\": token_type_ids,\n",
    "      \"attention_mask\": attention_masks,\n",
    "  }, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5b84c41a-7fb8-4a32-905c-c24ba9240904",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_examples(ds, limit=-1):\n",
    "    # 建立模型使用的数据集\n",
    "    input_ids_list = []\n",
    "    token_type_ids_list = []\n",
    "    attention_mask_list = []\n",
    "    label_list = []\n",
    "    if (limit > 0):\n",
    "        ds = ds.take(limit)\n",
    "  \n",
    "    for index, row in ds.iterrows():\n",
    "        review = row[\"Abstract\"]\n",
    "        label = row[\"y\"]\n",
    "        bert_input = convert_example_to_feature(review)\n",
    "  \n",
    "        input_ids_list.append(bert_input['input_ids'])\n",
    "        token_type_ids_list.append(bert_input['token_type_ids'])\n",
    "        attention_mask_list.append(bert_input['attention_mask'])\n",
    "        label_list.append([label])\n",
    "    return tf.data.Dataset.from_tensor_slices((input_ids_list, attention_mask_list, token_type_ids_list, label_list)).map(map_example_to_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4b773d82-208e-44da-8184-daa8ce1a4225",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(df):\n",
    "    train_set, test_set = train_test_split(df, \n",
    "        stratify=df['Type'],\n",
    "        test_size=0.2, \n",
    "        random_state=42)\n",
    "\n",
    "    return train_set, test_set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "82226742-ffab-4d58-8209-70c175509695",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160\n",
      "40\n",
      "Index(['Type', 'Authors', 'Title', 'Year', 'Electronic-resource-num',\n",
      "       'Abstract', 'Periodical', 'Paper_id', 'y'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:2212: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3/3 [==============================] - 23s 2s/step - loss: 1.3962 - accuracy: 0.2375 - val_loss: 1.3772 - val_accuracy: 0.2750\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 2s 646ms/step - loss: 1.3661 - accuracy: 0.3000 - val_loss: 1.3622 - val_accuracy: 0.4000\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 2s 644ms/step - loss: 1.3257 - accuracy: 0.4563 - val_loss: 1.3286 - val_accuracy: 0.3000\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 2s 642ms/step - loss: 1.2923 - accuracy: 0.4500 - val_loss: 1.2965 - val_accuracy: 0.3250\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 2s 643ms/step - loss: 1.2131 - accuracy: 0.6250 - val_loss: 1.2741 - val_accuracy: 0.4250\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 2s 646ms/step - loss: 1.1567 - accuracy: 0.6313 - val_loss: 1.2026 - val_accuracy: 0.5000\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 2s 645ms/step - loss: 1.0926 - accuracy: 0.7250 - val_loss: 1.1245 - val_accuracy: 0.6750\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 2s 646ms/step - loss: 1.0160 - accuracy: 0.8062 - val_loss: 1.0510 - val_accuracy: 0.7250\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 2s 649ms/step - loss: 0.9431 - accuracy: 0.8938 - val_loss: 0.9781 - val_accuracy: 0.7000\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 2s 647ms/step - loss: 0.8803 - accuracy: 0.8687 - val_loss: 0.9308 - val_accuracy: 0.7250\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.9308 - accuracy: 0.7250\n",
      "# evaluate test_set: [0.9307827949523926, 0.7250000238418579]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__': \n",
    "\n",
    "    # 参数\n",
    "    data_path = \"Leukemia.csv\" # 数据路径\n",
    "    model_path = \"bert-base-uncased\" #模型路径，建议预先下载\n",
    "\n",
    "    max_length = 64\n",
    "    batch_size = 64\n",
    "    learning_rate = 2e-5\n",
    "    number_of_epochs = 10\n",
    "    num_classes = 4 # 类别数\n",
    "\n",
    "    # 读数据\n",
    "    df_raw = pd.read_csv(data_path)    \n",
    "    abstract = df_raw['Abstract']\n",
    "    label = df_raw['Type']\n",
    "    \n",
    "    # 转换标签\n",
    "    df_label = pd.DataFrame({\"Type\":[\"AML\", \"ALL\", \"CML\", \"CLL\"],\"y\":list(range(4))})\n",
    "    df_raw = pd.merge(df_raw,df_label,on=\"Type\",how=\"left\")\n",
    "    # 划分数据\n",
    "    train_data, test_data = split_dataset(df_raw)\n",
    "    \n",
    "    print(len(train_data))\n",
    "    print(len(test_data))\n",
    "    print(test_data.keys())\n",
    "\n",
    "    # 分词器\n",
    "    tokenizer = BertTokenizer.from_pretrained(model_path)\n",
    "    # 训练数据集\n",
    "    ds_train_encoded = encode_examples(train_data).shuffle(50).batch(batch_size)\n",
    "\n",
    "    # 测试数据集\n",
    "    ds_test_encoded = encode_examples(test_data).batch(batch_size)\n",
    "\n",
    "    # 模型初始化\n",
    "    model = TFBertForSequenceClassification.from_pretrained(model_path, num_labels=num_classes)\n",
    "\n",
    "    # 使用Adam作为优化器\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate,epsilon=1e-08, clipnorm=1)\n",
    "    # 使用交叉熵作为损失函数\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "    metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n",
    "    model.compile(optimizer=optimizer, loss=loss, metrics=[metric])\n",
    "    # 训练模型\n",
    "    bert_history = model.fit(ds_train_encoded, epochs=number_of_epochs, validation_data=ds_test_encoded)\n",
    "    # 估算测试集效果\n",
    "    print(\"# evaluate test_set:\",model.evaluate(ds_test_encoded))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f6b9c267-ca8b-4e1a-a0a9-c3403b1ff4df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[8 0 0 2]\n",
      " [0 8 1 1]\n",
      " [6 0 4 0]\n",
      " [1 0 0 9]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# 得到模型预测结果\n",
    "res = model.predict(ds_test_encoded)\n",
    "pre = np.argmax(res[\"logits\"], axis=1)\n",
    "true = test_data['y']\n",
    "# 生成混淆矩阵\n",
    "cf = confusion_matrix(true, pre)\n",
    "print(cf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6031cb9f-deb4-41d9-95a5-6bc23221f25d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
